---
title: "Data Visualization Notes"
author: "Andrew Nalundasan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
## Set the default size of figures
## By default, show code for all chunks in the knitted document,
## as well as the output. To override for a particular chunk
## use echo = FALSE in its options.
knitr::opts_chunk$set(fig.width = 8, fig.height = 5, echo = TRUE)

## Load the libraries we will be using
library(gapminder)
library(here)
library(tidyverse)
library(socviz)
library(here)  # make it easier to work with files and subfolders while not needing to type full paths
library(vtable)
library(ggrepel)  # easier to work with text labels rather than using geom_text()
library(broom)  # to take model objects and turn pieces of them into data frames to use in ggplot
library(survival)  # survival data
```


```{r install, eval = FALSE}

## This code will not be evaluated automatically.
## (Notice the eval = FALSE declaration in the options section of the
## code chunk)

# my_packages <- c("tidyverse", "broom", "coefplot", "cowplot",
                 "gapminder", "GGally", "ggrepel", "ggridges", "gridExtra",
                 "here", "interplot", "margins", "maps", "mapproj",
                 "mapdata", "MASS", "quantreg", "rlang", "scales",
                 "survey", "srvyr", "viridis", "viridisLite", "devtools")

# install.packages(my_packages, repos = "http://cran.rstudio.com")

```

# Set Up Project and Load Libraries

To begin we must load some libraries we will be using. If we do not load them, R will not be able to find the functions contained in these libraries. The tidyverse includes ggplot and other tools. We also load the socviz and gapminder libraries.

# Look at Data

+ The graphs you make are meant to be looked at by someone
+ When making graphs, there is only so much that R can do to keep me on the right track
+ Need to begin cultivating my own good sense about graphs now
+ Perceptual tendencies can be honestly harnessed to make our graphics more effective
+ **Scatterplot** - shows the relationship between two quantities
+ What makes figures bad? 3 varieties:

    + Aesthetic
    + Substantive
    + Perceptual

+ Avoid content-free decoration, including chartjunk aka CLUTTER
+ Visually unique, "infographic" - style graphs are more memorable than more standard statistical visualizations
+ median > raw data

    + Rather look at the trend of an average score, rathern than the trend for the highest possible score
    
+ Relative comparisons need a stable baseline
+ Our ability to distinguish shades of brightness is not uniform
+ **Luminance** - brightness
+ **Chrominance** - intensity
+ **Diverging Scale** - where the steps away from the midpoint are perceptually even in both directions
+ **Qualitative Palette** - easiliy distinguishable colors but also have the same valence for the viewer
+ We should not pick colors in an ad hoc way
+ **Shape** and **color** are two distinct *channels* that can be used to encode information visually
+ Gestalt principles: 

    + *Proximity* - things that are spatially near to one another seem to be related
    + *Similarity* - Things that look alike seem to be related
    + *Connection* - Things that are visually tied to one another seem to be related
    + *Continuity* - Partially hidden objects are completed into familiar shapes
    + *Closure* - Incomplete shapes are perceived as complete
    + *Figure and ground* -  Visual elements are taken to be either in the foreground or in the background
    + *Common fate* - Elements sharing a direction of movement are perceived as a unit
    
+ A scatterplot is a visual *representation* of data, not a way to magically transmit pure understanding
+ There are better and worse ways of visually representing data when the task the user must perform involves estimating and comparing values within the graph
+ We tend to misjudge quantities encoded as *angles*
+ Often, the main audience for your visualizations is myself
+ Working with ggplot():

    1. Must give some information to the ggplot() function
    2. Must choose a geom_() function

# Get Started

+ *Install* package only once, but load the library() each session
+ In R, everything we deal with has a name
+ Almost everything is some kind of object
+ c() is a function: for 'combine' or 'concatenate'

    + Take a sequence of comma separate things inside the () and join them together into a vector where each element is still individually accessible
    
+ Function: special kind of object that can perform actions for me

    + Produces output based on the input it receives
    
```{r}
c(1, 2, 3, 1, 3, 5, 25)  # sends to console and output is provided

# assign to objects
my_numbers <- c(1, 2, 3, 1, 3, 5, 25)
your_numbers <- c(5, 31, 71, 1, 3, 21, 6)
```

## You do things using functions

```{r}
# practice with functions
mean(x=my_numbers)
mean(x=your_numbers)
mean(my_numbers)

my_summary <- summary(my_numbers)
my_summary
```

+ Packages save you from reinventing the wheel
+ Things are done in R by creating and manipulating named objects
+ outputs are as expected

```{r}
# operations
table(my_numbers)
sd(my_numbers)
my_numbers * 5
my_numbers + 1
my_numbers + my_numbers  # vectorized operation - vectors of the same length
```

+ *Vectorized* operation - vectors of the same length are added together (manipulated somehow)

```{r}
# practice with classes
class(my_numbers)
class(my_summary)
class(summary)

# manipulate classes
my_new_vector <- c(my_numbers, "Apple")
my_new_vector
class(my_new_vector)
```

+ Adding "Apple" changes the entire vector from *number* type to *character* type
+ Character strings cannot be used in calculations


+ *Matrix* - consists of rows and columns of numbers
+ *Data Frame* - rectangular table consisting of rows (of observations) and columns (of variables)

    + Columns can be of different classes

```{r}
titanic
class(titanic)

# selecting particular elements in a df
titanic$percent
```

+ *Tibble* - 

    + used to store variables of different classes all together in a single table of data
    + Do more to let us know about what they contain
    + More friendly when interacted with from the console
    
```{r}
titanic_tb <- as_tibble(titanic)
titanic_tb
```

+ To see inside an object, ask for its *structure*
+ *vector* is just a sequence of numbers

```{r}
str(my_numbers)
str(my_summary)
```

## Get data into R

```{r}
url <- "https://cdn.rawgit.com/kjhealy/viz-organdata/master/organdonation.csv"

organs <- read_csv(file=url)
```

+ "Column specification" - tells us that read_csv() function has assigned a class to each column of the object it created from the CSV file
+ It is helpful to know what class each column / variable is

    + A variable's class determines what sort of operations can be performed on it
    
+ read_csv() will not classify variables as *factors* unless it's told to
+ You will need to take care that any labeled variables imported into R are coded properly, so that you do not end up mistakenly using missing data in your analysis
+ "Tidy" format:

    + *long* rather than *wide* format
    + Every observation a row
    + Every variable a column
    
## Make first figure
    
```{r}
gapminder
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point()
```

# Make a Plot

+ Visualizing data with ggplot *always* involves the same sequence of steps
+ The way you use ggplot to think about the logical structure of the plot
+ *aesthetics* - logical connections between the data and the plot elements

## How Ggplot works 

+ Steps to creating ggplots: 

    1. Tell ggplot() function what the data is and how the variables in the data logically map onto the plot's aesthetics
    2. Take the result and say what general sort of plot wished to create, or *geom*
    
+ Plots: 

    + geom_point() - scatterplot
    + geom_bar() - bar plot
    + geom_boxplot() - boxplot
    
+ ggplot() + geom() yields a plot
+ the rest of it is just details

+ Specify the details: 

    + scales
    + labels
    + legends
    + axes
    + etc.

## Tidy Data

+ Tidy data:

    + *long-format* - every variable is a column, every observation is a row
    + *wide-format* - some variables are spread out across columns
    + ggplot wants data in *long-format*
    
+ tidy data is much more straightforward to work with when it comes to specifying the mappings that you need to coherently describe plots

## Mappings link data to things you see

```{r}
# look at the data
gapminder
```

+ Plot life expectancy against per capita GDP for all country-years in the data

```{r}
p <- ggplot(data = gapminder)

```

+ data still needs to be mapped
+ *mapping* - tell ggplot which variables in the data should be represented by which visual elements in the plot
+ ggplot also doesn't know what sort of plot we want (*geom*)

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
```

+ here, we've given ggplot 2 arguments: 

    1. data
    2. mapping
    
+ the *data* argument tells ggplot where to find the variables it is about to use

    + any mentions of variables will be searched for in the specified *data*
    
+ *mapping* argument is not a data object, not even a character string. It's a *function*
+ this aes() function call says:

    + "The variable on the x-axis is going to be *gdpPercap* and the variable on the y-axis is going to be *lifeExp*"
    
+ *mapping = aes(...)* argument *links variables to things you will see* on the plot
+ *mapping* does not directly say what particular colors or shapes will be on the plot
+ *mapping* says which *variables* in the data will be *represented* by visual elements on the plot
+ we need to add a *layer* to the plot

```{r}
p + geom_point()
```

## Build plots layer by layer

+ Conceptually, we will always follow the same set of steps:

    1. Tell the ggplot() function what our data is
    2. Tell ggplot() *what* relationships we want to see. For convenience we will put the results of the first two steps in an object called p
    3. Tell ggplot *how* we want to see the relationships in our data
    4. Layer on geoms as needed, by adding them to the p object one at a time
    5. Use some additional function sto adjust scales, labels, tickmarks, titles. 
    
+ default plots - coordinate system typically cartesian
+ *cartesian* coordinate system - plane defined by an x-axis and a y-axis
+ typically in R - *functions* take *objects* as *inputs* and produce *objects* as *outputs*

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_smooth()
```

+ geom_smooth() calculated a smoothed line for us and shaded in a ribbon showing the standard error for the line

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() + geom_smooth()
```

+ see the data points and the smoothed line together. 
+ R console returns a message regarding "gam". 

    + R has fit a generalized additive model
    + This implies that there are other models that geom_smooth() understanding
    + let's try adding method = 'lm' (linear model)


```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() + geom_smooth(method = 'lm')
```

+ It's possible to give geoms separate instructions that they will follow
+ Let's try to take the log to spread out the distribution on the left side of this plot
+ 'scale_x_log10()' - scales the x-axis of a plot to a log 10 basis


```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() + geom_smooth(method = 'gam') + scale_x_log10()
```

+ This plot is different from in the book. 
+ To match the plot in the book, change to 'method = 'lm''.
+ scale_ functions can be applied to format the tick-marks

+ Gain access to all functions within a library, load the library via library()
+ Use just 1 function from a library, use :: to grab that specific function
+ syntax - 

    + thepackage::thefunction
    
```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() + 
  geom_smooth(method = 'lm') + 
  scale_x_log10(labels = scales::dollar)
```

+ scale transformations: 

    1. Possible to directly transform x- or y- axis by adding something like "scale_x_log10()" or "scale_y_log10()" to the plot
        + The x- or y- axis will be transformed
        + By default, the tick-marks on the axis will be labeled using *scientific notation*
    2. Possible to gives these "scales_" functions a "labels" argument that reformats the text printed underneath the tick-marks on the axes.
    
## Mapping aesthetics vs setting them

+ *aesthetic mapping* - specifies that a variable will be expressed by one of the available visual elements, such as size, color, or shape

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent))
```

+ this command says "the portery 'color' will represent the variable *continent*"
+ aka - "color will map *continent*
+ if we wanted all the points to be purple, it is NOT done via *mapping* function

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = "purple"))
p + geom_point() + geom_smooth(method = "loess") + scale_x_log10()
```

+ *aesthetic* - mapping of variables in your data to properties you can see on the graph
+ aes() function is where the mapping is specified, and the function is trying to do its job

    + aes() is trying to treat "purple" as if it were a variable
    + a variable should have as many observations as there are rows in the data
    + aes() is for mappings only - do not use to change properties in a particular value
    
```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(color = "purple") + geom_smooth(method = "loess") + scale_x_log10()
```

+ R knows what color "purple" is when passed into geom_point()
+ R doesn't know what color "purple" is when passed into the *aesthetic*

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(alpha = 0.3) + geom_smooth(color = "orange", se = FALSE, size = 2, method = "lm") + scale_x_log10()
```

+ updated size from 8 to 2
+ *alpha* controls how transparent the object will appear when drawn. From scale 0-1
+ transparency helps to make it easier to see where the bulk of observations are located

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(alpha = 0.3) + 
  geom_smooth(method = "gam") + 
  scale_x_log10(labels = scales::dollar) + 
  labs(x = "GDP Per Capita", y = "Life Expectancy in Years",
       title = "Economic Growth and Life Expectancy", 
       subtitle = "Data points are country-years", 
       caption = "Source: Gapminder.")
```

+ Make a nicer plot: 
    
    1. Set *alpha* of the points to a low value
    2. Make nice x- and y- axis labels
    3. Add a title, subtitle, and caption
    
+ Unless told otherwise, all geoms layered on top of the original plot object will inherit that object's mappings (everything inherits from "p")

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent))
p + geom_point() + geom_smooth(method = "loess") + scale_x_log10()
```

+ standard error ribbons are all gray. can be adjusted using *fill* 
+ *color* aesthetic affects appearance of lines and points
+ *fill* is for the filled areas of bars, polygons, and standard error ribbon

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp, color = continent, fill = continent))
p + geom_point() + geom_smooth(method = "loess") + scale_x_log10()
```

+ Legend: the smoother understand both *color* (for the line itself) and *fill* (for the shaded standard error ribbon)

## Aesthetics can be mapped per Geom

+ By default, geoms inherit their mappings from ggplot()

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = continent)) + 
  geom_smooth(method = "loess") + 
  scale_x_log10()
```

+ Legend : the points have *color*

    + Colored line and shaded box are both absent
    + We only see a legend for the mapping of *color* to *continent* in *geom_point()
    
+ Smoothing line drawn by geom_smooth() is set by default to bright blue with default shaded ribbon to gray

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = log(pop))) + scale_x_log10()
```

+ Also possible to map continuous variables (rather than just categorical variables) to the *color* aesthetic too
+ When taking the log() of some data, ggplot produces a gradient scale

## Save your work

+ control size and format of a code chunk: 

    + #knitr::opts_chunk$set(fig.width = 8, fig.height = 5)
    + this sets default size of plots within the .Rmd document
    + this indicates 8x5 figures
    
```{r example, fig.width = 12, fig.height = 9}
p + geom_point()

# save the most recent plot
ggsave(filename = "../03_visuals/my_figure.png")
ggsave(filename = "../03_visuals/my_figure.pdf")

```

+ Easiest way to save figures when using ggplot() is to call ggsave()
+ Andrew's tip: set working directory to "03_visuals" folder before calling ggsave()

    + When working director is set to this folder, ggsave() will save the file in this folder directly
    + When running code directly from .Rmd, use folder path trick to save files to the intended folder
        + "../03_visuals/filename.png"
        
```{r}
p_out <- p + geom_point() + geom_smooth(method = "loess") + scale_x_log10()

ggsave("../03_visuals/my_figure.pdf", plot = p_out)

# save file using here()
ggsave(here("03_visuals", "lifeexp_vs_gdp_gradient.pdf"), plot = p_out)
```

+ useful to have a separate folder for just visuals
+ name figures similar to variables and objects - make them meaningful
+ do not include special characters in figure file names including: 
    
    + ', `, ' ', /, \, "
    
+ save file using "here()" and specify which folder within the folder structure: "03_visuals"

+ Important distinction between *vector* format vs. *raster* format
    
    + *vector* format:
        + PDF or SVG file types
        + stored as a set of instructions about lines, shapes, colors, and their relationships
        + Viewing software: Adobe Acrobat / Apple Preview apps for PDFs
        + Can be resized without being distorted
        + Good choice for high quality images
    + *raster* format: 
        + JPG and PNG file types
        + stored images as a grid of pixels of predefined size with information about the location, color, brightness, of each pixel in the grid
        + raster cannot be easily resized without being pixelated or distorted
        + JPG and PNG standard file types for images on the web
        
+ Important to know what the figure will be used for and in what setting/medium of communication

```{r}
# use ggsave() to explicitly set the height and width of the plot in the chosen units
ggsave(here("03_visuals", "lifeexp_vs_gdp_gradient.pdf"), plot = p_out, height = 8, width = 10, units = "in")
```

## Where to go next

1. Explore with ordering of geom_point() and geom_smooth(). How is this helpful with drawing plots?

```{r}
p + geom_point()
p + geom_smooth()
p + geom_point() + geom_smooth()
# geom_smooth() is layered ABOVE geom_point()
p + geom_smooth() + geom_point()
# geom_smooth() is layered BELOW geom_point()
```

**Comments**
+ the last geom element is layered on top. It's like layering layers on top of one another. First layer in is on the bottom. Last geom layer called is at the top of the stack. 
+ this would be useful if I know which layer I need to stand out the most, and which layers will be used as background to help build the story

2. Change mappings of aes() function. What does switching up the mappings tells me about the units of observation in the dataset?

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = pop, y = lifeExp))
p + geom_point() + 
  geom_smooth() +
  scale_x_log10()
```

**Comments**

+ when plotting lifeExp against pop rather than GDP, it appears that the distribution of observations resemble a random distribution such as poisson. 
+ geom_smooth is almost flat. It is a slightly positive trend
+ I don't know what this tells me about the unit of observation in the dataset 

3. Try alternative scale mappings like scale_x_sqrt() and scale_x_reverse()

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))

# scale_x_log10()
p + geom_point() + 
  geom_smooth() + 
  scale_x_log10() + 
  ggtitle("log x 10")

# scale_x_sqrt()
p + geom_point() + 
  geom_smooth() + 
  scale_x_sqrt() + 
  ggtitle("log x sqrt")


# scale_x_reverse()
p + geom_point() + 
  geom_smooth() + 
  scale_x_reverse() +
  ggtitle("log x reverse")

# scale_y_log10()
p + geom_point() + 
  geom_smooth() + 
  scale_y_log10() +
  ggtitle("log y 10")

# scale_y_sqrt()
p + geom_point() + 
  geom_smooth() + 
  scale_y_sqrt() +
  ggtitle("log y sqrt")

# scale_y_reverse()
p + geom_point() + 
  geom_smooth() + 
  scale_y_reverse() +
  ggtitle("log y reverse")

```

**Comments**

+ scale_x_log10():

    + takes the log of the x-axis and spreads out the observations that are clumped up

+ scale_x_sqrt():

    + I guess instead of taking the log of the x axis, this takes the sqare root of the x axis
    + x-axis values are a lot smaller than the log
    + points are clumped up slightly towards left of the plot

+ scale_x_reverse():

    + makes x-axis read in reverse (origin is at bottom right corner rather than bottom left corner)
    + plotted with default settings to x-axis, just flipped (no log and no square root applied)
    + not sure when reversing would make sense

+ scale_y_log10():

    + this doesn't seem to take the log of the y-axix. 
    + this looks similar to the default plot on the y-axis - observations hella clumped up

+ scale_y_sqrt():

    + not much difference from y_log scaling - observations just a little spread out
    + more of a curvy shape compared to log
    + not as drastic a change as between x_log10 vs. x_sqrt


+ scale_y_reverse():

    + as expected, y-axis is reversed
    + origin is at top left rather than bottom left
    + not sure when reversing would make sense
    
4. Map color to year instead of continent. What are the results? Think about what class the object year is. 

```{r}
p <- ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp))

# color mapped to continent
p + geom_point(mapping = aes(color = continent)) + 
  geom_smooth(method = "loess") + 
  scale_x_log10()

# color mapped to year
p + geom_point(mapping = aes(color = year)) + 
  geom_smooth(method = "loess") + 
  scale_x_log10()

```

**Comments**
+ color by year turned the color scheme to a gradient
+ dark colors for early in time, light colors more recent in time
+ class of year is "integer"
+ class of continent is "factor"
+ we get gradient of color because integer is a continuous variable
+ when color is mapped to a factor variable, we get discrete classes of each factor

5. What happens when mapping color to "factor(year)"?

```{r}
p + geom_point(mapping = aes(color = factor(year))) + 
  geom_smooth(method = "loess") + 
  scale_x_log10()
```

**Comments**
+ when mapping color to factor(year), R changes the "year" variable from an integer to a factor variable. 
+ R then plots every year as a separate factor and we end up with a factor for every single year
+ might as well still be a gradient because there are so many

6. Improve figure 3.13. What are we gaining and losing by ignoring the temporal and country-level structure of the data? 

```{r}
p <- ggplot(gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(alpha=0.3) + 
  geom_smooth(method="lm") + 
  scale_x_log10(labels = scales::dollar) + 
  labs(x = "GDP Per Capita", y = "Life Expectancy in Years", 
       title = "Economic Growth and Life Expectancy", 
       subtitle = "Data points are country-years", 
       caption = "Source: Gapminder.")

```

**Comments**
+ what does "country-years" mean?
+ perhaps we could add a layer to show countries or continents?
+ there are 142 countries in the gapminder dataset. That's too many to display

**Chapter Wrap Up**
+ It's always worth trying something
+ main flow of ggplot is always the same

    1. start with a table of data
    2. map the variables I want to display to aesthetics like position, color, or shape
    3. Choose 1 or more geoms to draw the graph


# Show the Right Numbers

## Introduction

+ Focus on ggplot's central workflow
+ *geoms* - functions that make particular kinds of plots
+ common problem - when an aesthetic is mistakenly set to a *constant value* instead of being mapped to a *variable*
+ *grouping* - internal structure of the data
+ *faceting* - break up data into pieces for a plot
+ *transforming* - get ggplot to perform some calculations on or summarize the data before producing the plot

## Colorless Green Data Sleeps Furiously

+ grammar of graphics - set of rules for producing graphics from data, taking pieces of data and mapping them to geometric objects that have aesthetic attributes together with further rules for transforming the data if needed, adjusting scales, and projecting the results onto a different coordinate system
+ syntax and semantics will make or break your plots

## Grouped Data and the "Group" Aesthetic

+ Plot the trajectory of life expectancy over time for each country in gapminder
+ geom_line() - will draw lines by connecting observations in order of the variable on the x-axis

```{r}
p <- ggplot(gapminder, mapping = aes(x=year, y=gdpPercap))
p + geom_line()
```

**Comments**
+ This is not what was expected. 
+ This looks like a bar chart
+ ggplot does not know that the yearly observations in the data are grouped by country - I must specify this
+ in this plot, geom_line() tries to join up all the lines for each particular year in the order they appear in the dataset
+ ggplot does not know that the very first observation belongs to Afghanistan in 1952
+ ggplot does not know to look for the second observation for Afghanistan in 1953
+ ggplot plots out all 1952 observations moving alphabetically (Afghanistan -> Zimbabwe) before moving to the next year
+ when bugs occur in ggplot, the reason is almost always that something has gone wrong in the mapping between the data and aesthetics for the gom being used

Use the "group" aesthetic to tell ggplot explicitly about this country-level structure

```{r}
p <- ggplot(gapminder, mapping = aes(x=year, y=gdpPercap))
p + geom_line(aes(group = country))
```

**Comments**
+ still hella rough, but data is displaying correctly
+ each line represents the trajectory of a country over time
+ giant outlier is Kuwait
+ "group" aesthetic usually only needed when the *grouping* information you need to tell ggplot about is not built into the variables being mapped
+ grouping is already clear for categorical/factor variables
+ when mapping x to "year", there is no information in "year" that tells ggplot that it is grouped by country

## Facet to Make Small Multiples

+ *facet* - technique that allows a lot of information to be presented compactly and in a consistently comparable way
+ *facet* - way of organizing a series of geoms
+ R's "formula" syntax when using the "tilde character": ~
+ term in the formula: the variable we want the data to be broken up by

```{r}
p <- ggplot(gapminder, mapping = aes(x=year, y=gdpPercap))
p + geom_line(aes(group = country)) +
  facet_wrap(~continent)
```

**Comments**
+ using facet wrap minimizes the duplication of axis labels and other scales
+ use "ncol" to control the number of columns used to lay out the facets
+ can layer on additional geoms if needed

```{r}
p <- ggplot(gapminder, mapping = aes(x=year, y=gdpPercap))
p + geom_line(color="gray70", aes(group = country)) +
  geom_smooth(size = 1.1, method = "loess", se = FALSE) +
  scale_y_log10(labels=scales::dollar) +
  facet_wrap(~ continent, ncol = 5) +
  labs(x = "Year", 
       y = "GDP per capita", 
       title = "GDP per capita on Five Continents")
```

**Comments**
+ summary of plot:

    + brings together a aesthtic mapping of x and y variables
    + brings together a grouping aesthetic (country)
    + brings together 2 geoms (lineplot + smoother)
    + y-axis is log-transformed with appropriate tick labels
    + brings together a faceting variable (continent)
    + includes axis labels and a title
    
+ facet_wrap() is best used when wanting to facet something based on a **single categorical variable**
+ if cross-classifying data by 2 categorical variables, use **facet_grid()**

## Working with GSS Data

+ gapminder:
    
    + gapminder consists mostly of *continuous* variables
    + *continuous* variables can take any value across a large range and vary smoothly
    + only *categorical* variable is "continent"
        + unordered *categorical* variable
        + each country belongs to a continent, but the continents themselves have no natural ordering (other than alphabetical)
        
+ GSS:

    + long-running survey of American adults that asks about a range of topics of interest to social scientists
    + contains many *categorical* measures
    + unordered *categorical* data:
        + ethnicity
        + sex
    + ordered *categorical* data: 
        + educational attainment
        + opinion questions asked in yes/no terms
        + questions answered on a point scale, with "neutral" in the middle
    + *numeric* variables
        + number of children - range of integers in a narrow range
            + could also be represented on a scale with option like "6+ children"
    + *continuous* variables are often obtainable only as ordered categories
        + income
            + 0-30k, 31-60k, 61-90k, etc.
            
```{r}
# look at the data
glimpse(gss_sm)
head(gss_sm, 10)
summary(gss_sm)
vtable(gss_sm)  # vtable is just a pretty version of glimpse, populates in "Viewer" pane
class(gss_sm)
```

Make a smoothed scatterplot of the relationship between the age of the respondent and the number of children they have

```{r}
p <- ggplot(gss_sm, mapping = aes(x = age, y = childs))
p + geom_point(alpha = 0.2) +
  geom_smooth() +
  facet_grid(sex ~ race)
```

**Comments**
+ multipanel layouts are especially effective when used to summarize continuous variation acros 2+ categorical variables, with the categories ordered in some sensible way

```{r}
p <- ggplot(gss_sm, mapping = aes(x = age, y = childs))
p + geom_point(alpha = 0.2) +
  geom_smooth() +
  facet_grid(sex ~ race + degree)
```

**Comments**
+ Possible to add to the two-way comparison (sex ~ race + degree)
+ Multiple dimensions of plots like this will quickly become very complicated if thevariables have more than a few categories each

## Geoms Can Transform Data

+ geom_smooth() will add a trendline to a figure

    + methods: 
        + "loess"
        + "lm"
        + Generalized Additive Model

+ some geoms plot our data directly on the figure, like geom_point()
+ every 'geom' function has a default 'stat' function
+ every 'stat' function has a default 'geom' function
+ we sometimes want to calculate different stats using different geoms

```{r}
p <- ggplot(data = gss_sm, mapping = aes(x = bigregion))
p + geom_bar()
```

**Comments**
+ Bar chart provides a count of the number of individual observations in the data set by region of the US
+ y-axis, "count" has bee calculated for me
+ default stat function for geom_bar(): stat_count()
+ stat_count() calculates 2 stats: "count" and "prop" (proportion)

```{r}
p <- ggplot(data = gss_sm, mapping = aes(x = bigregion))
p + geom_bar(mapping = aes(y = ..prop..))
```

**Comments**
+ produces chart of relative frequencies rather than counts by using "prop" statistic instead
+ To make certain these temporary variables won't be confused with others we are working with, their names begin and end with two periods
+ 'dunder period' !!!
+ when calling this, it will look like: 

    + <mapping> = <..statistic..>
    
```{r}
p <- ggplot(gss_sm, mapping = aes(x = bigregion))
p + geom_bar(mapping = aes(y = ..prop.., group = 1))
```

**Comments**
+ this chart shows that the bars *sum* to 1

    + so that we get the number of observations per continent as a proportion of the total number of observations

+ ggplot *ignores* the x-categories when calculating denominator of the proportion and use the total number observations instead
+ specify "group = 1" inside aes() call

    + value of 1 is a "dummy group" that tells ggplot to use the whole dataset when establishing the denominator for its prop calculations
    
```{r}
table(gss_sm$religion)
```

```{r}
p <- ggplot(gss_sm, mapping = aes(x = religion, color = religion))
p + geom_bar()

p <- ggplot(gss_sm, mapping = aes(x = religion, fill = religion))
p + geom_bar() + guides(fill = FALSE)
```

**Comments**
+ "fill" is for painting the insides of shapes
+ mapping "religion" to "color", only the border lines of the bars will be assigned colors, and the insides remain gray
+ we have mapped 2 aesthetics to the same variable

    + both 'x' and "fill" are mapped to "religion"

+ default is to show a legend for the color variable
+ guides() controls whether guiding information about any particular mapping appears or not
+ guides(fill = FALSE) will remove the legend

    + this assumes that the audience does not need the legend to figure out what the figure is telling
    
## Frequency Plots the Slightly Awkward Way

+ use geom_bar() to cross-classify 2 categorical variables
+ Best Practice:  calculate the table first before passing the results along to ggplot to graph
+ geom_bar() - output is controlled by the "position" argument

```{r}
p <- ggplot(gss_sm, mapping = aes(x = bigregion, fill = religion))
p + geom_bar()
```

**Comments**

+ default output is stacked bar chart with counts on the y-axis
+ stacked bar charts - it is difficult for readers on the chart to compare lengths and areas on an unaligned scale
+ better alternative: set "position" argument to "fill" (different from "fill" *aesthetic*)


```{r}
p <- ggplot(gss_sm, mapping = aes(x = bigregion, fill = religion))
p + geom_bar(position = "fill")
```

**Comments**
+ now all bars are same height, which is easier to make comparisons across groups

```{r}
p <- ggplot(gss_sm, mapping = aes(x = bigregion, fill = religion))
p + geom_bar(position = "dodge")
```

**Comments**
+ ggplot places the bars side-by-side as intended but changes the y-axis back to a *count* of observations
+ we wanted proportions, not counts

```{r}
p <- ggplot(gss_sm, mapping = aes(x = bigregion, fill = religion))
p + geom_bar(position = "dodge", mapping = aes(y = ..prop..))
```

**Comments**
+ there seems to be an issue with grouping

```{r}
p <- ggplot(gss_sm, mapping = aes(x = bigregion, fill = religion))
p + geom_bar(position = "dodge", mapping = aes(y = ..prop.., group = religion))
```

**Comments**
+ outputs a bar chart where values of "religion" are broken down across regions, with a proportion showing on the y-axis
+ bars do not sum to 1 within each reagion
+ bars for any particular religion sum to 1 *across* regions
+ nearly 50% of those who said they were Protestant live in the South
+ just over 10% saying they were Protestant live in the Northeast
+ over 50% of Jewish live in the Northeast, compared to 25% in the South


```{r}
p <- ggplot(gss_sm, mapping = aes(x = religion))
p + geom_bar(position = "dodge", mapping = aes(y = ..prop.., 
                                               group = bigregion)) + 
  facet_wrap(~bigregion, ncol = 2)
```

**Comments**
+ don't try to force geom_bar() to do all the work in a single step
+ Ask ggplot to give us a proportional bar chart of religious affiliation, then facet that by region

## Histograms and Density Plots

+ Different geoms transform data in different ways, but ggplot's vocabulary for them is consistent
+ Histogram - way of summarizing a continuous variable by chopping it up into segments or "bins" and counting how many observations are found within each bin

    + must decide how finely to bin the data
    
+ Bar chart - categories are given to us going in
+ dataset: midwest

    + information abour counties in midwestern states
    + area measured in square miles
    
```{r}
p <- ggplot(midwest, mapping = aes(x = area))
p + geom_histogram()
```

**Comments**
+ message: "stat_bin()" using "bins = 30". Pick better value with "binwidth".

    + set number of bins in argument
    + 30 bins chosen by R by default
    
```{r}
p <- ggplot(midwest, mapping = aes(x = area))
p + geom_histogram(bins = 10)
```

**Comments**
+ similar to geom_bar(), new variable "count" auto calculated for y-axis
+ when drawing histograms, it's worthwhile to experiment with bins
+ histograms - summarize single variables

```{r}
# character vector of 2 states
oh_wi <- c("OH", "WI")

# use subset() to take data and filter it so that we select only rows whose "state" name is in this vector
# %in% operator is a convenient way to filter on more than one term in a variable when using subset()
p <- ggplot(data = subset(midwest, subset = state %in% oh_wi),
            mapping = aes(x = percollege, fill = state))
p + geom_histogram(alpha = 0.4, bins = 20)
```

**Comments**
+ subset the data to pick out just 2 states
+ subset() - take our data and filter it so that we select only rows whose "state" name is in this vecotor
+ %in% - filer on more than one term in a variable when using subset()

```{r}
p <- ggplot(midwest, mapping = aes(x = area))
p + geom_density()
```

**Comments**
+ geom_density() - alternative for when working with a continuous variable, an alternative to binning the data and making a histogram 
+ make baselines of the density curves go away: 

    + geom_line(stat = "density")
    + unable to use "fill" when doing this
    
```{r}
p <- ggplot(midwest, mapping = aes(x = area, fill = state, color = state))
p + geom_density(alpha = 0.3)
```

**Comments**
+ many options to use in these arguments
+ count-based defaults computed by the stat_ functions will return proportional measures if asked
+ ..count.. - density * number points

    + this can be used in stacked density plots
    
```{r}
p <- ggplot(data = subset(midwest, subset = state %in% oh_wi),
             mapping = aes(x = area, fill = state, color = state))
p + geom_density(alpha = 0.3, mapping = (aes(y = ..scaled..)))
```

## Avoid Transformation When Necessary

+ geom_bar() does its calculations on the fly using stat_count() behind the scenes to produce the counts or proportions it displays
+ Often, our data is already a summary table

    + This can happen when we have computed a table of marginal frequencies or percentages from the original data
    
```{r}
titanic
```

**Comments**
+ this table already provides percentage values in a summary table
+ we no longer have any need for ggplot to perform calculations

```{r}
p <- ggplot(data = titanic, mapping = aes(x = fate, y = percent, fill = sex))
p + geom_bar(position = "dodge", stat = "identity") + 
  theme(legend.position = "top")
```

**Comments**
+ stat = "identity" tells geom_bar() not to do any default calculations. We're already working with proportions and counts.
+ geom_col() is the same thing as geom_bar(), but assumes "stat = "identity"" as default

    + use this geom when don't need any calculations done on the plot
    
+ stat = "identity" - means "don't do any summary calculations"
+ position = "identity" - "just plot the values as given" 

    + plot a flow of positive and negative values in a bar chart
    + alternative to a line plot
    + often seen in public policy settings where changes relative to some threhold level or baseline are of interest
    
```{r}
oecd_sum
```

```{r}
p <- ggplot(data = oecd_sum, mapping = aes(x = year, y = diff, fill = hi_lo))
p + geom_col() + guides(fill = FALSE) + 
  labs(x = NULL, y = "Difference in Years", 
       title = "The US Life Expectancy Gap", 
       subtitle = "Difference between US and OECD average life expectancies, 1960-2015",
       caption = "Data: OECD. After a char by Christopher Ingraham, 
       Washington Post, December 27th 2017.")
```

**Comments**
+ default action for geom_col() sets stat = "identity" and position = "identity"

## Where to Go Next

1. Experiment with different ways to facet gapminder data.

    + Plot population and per capita GDP while faceting on year
    + Facet on "country" but anticipate heaps of panels
        + Assign plot to an object and save as PDF. Experiement with height and width dimensions
        
```{r}
p <- ggplot(gapminder, mapping = aes(x = year, y = gdpPercap))
p + geom_line(aes(group = country)) + 
  facet_wrap(~ continent) + 
  labs(title = "facet on continent")

p + geom_line(aes(group = country)) + 
  facet_wrap(~ year) + 
  labs(title = "facet on year")

massive_facet <- p + geom_line(aes(group = country)) + 
  facet_wrap(~ year) + 
  labs(title = "facet on country")

ggsave(here("03_visuals", "massive_facet.pdf"), plot = massive_facet)


```

**Comments**

+ easy to get overwhelmed by facets if too many categories to plot and deal with

2. What is difference between "facet_grid(sex ~ race)" vs. "facet_grid(~ sex + race)"

```{r}
p <- ggplot(gss_sm, mapping = aes(x = age, y = childs))
p + geom_point(alpha = 0.2) +
  geom_smooth() + 
  facet_grid(sex ~ race) + 
  labs(title = "facet_grid(sex ~ race)")

p + geom_point(alpha = 0.2) +
  geom_smooth() + 
  facet_grid(~ sex + race) + 
  labs(title = "facet_grid(~ sex + race)")
```

**Comments**

+ "~ sex + race" breaks up the grid to have a separate column for each combination of "sex" and "race"
+ "sex ~ race" breaks up the grid to have one row for each category of "sex" and a separate column for each "race"

3. Investigate difference between "facet_wrap(~ sex + race) vs. "facet_grid(~ sex + race)"

```{r}
p + geom_point(alpha = 0.2) +
  geom_smooth() + 
  facet_wrap(~ sex + race) + 
  labs(title = "facet_wrap(~ sex + race)")

p + geom_point(alpha = 0.2) +
  geom_smooth() + 
  facet_grid(~ sex + race) + 
  labs(title = "facet_grid(~ sex + race)")
```

**Comments**

+ facet_wrap - breaks up "sex" categories into separate rows by default

    + lays out results in a wrapped 1-dimensional table
    
+ facet_grid - by default, outputs 1 row of all data

    + lays out results in a fully cross-classified grid

4. Replace visuals the call "geom_histogram()" with "geom_freqpoly()" instead and see the difference

```{r}
# character vector of 2 states
oh_wi <- c("OH", "WI")

# use subset() to take data and filter it so that we select only rows whose "state" name is in this vector
# %in% operator is a convenient way to filter on more than one term in a variable when using subset()
p <- ggplot(data = subset(midwest, subset = state %in% oh_wi),
            mapping = aes(x = percollege, fill = state))
p + geom_histogram(alpha = 0.4, bins = 20) + 
  labs("geom_histogram()")

p + geom_freqpoly(alpha = 0.4, bins = 20) + 
  labs("geom_freqpoly()")
```

**Comments**

+ geom_freqpoly() draw lines instead of bars (bins) to connect counts. 
+ This is a "frequency polygon"

5. Play with geom_bind2d() to make a histogram with mapped x and y. Use gapminder data. Provide bins for both x and y with "bins = c(20, 50)"

```{r}
p <- ggplot(gapminder, mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_bin2d(bins = c(20, 50)) + 
  geom_smooth(method="lm") + 
  scale_x_log10(labels = scales::dollar) + 
  labs(x = "GDP Per Capita", y = "Life Expectancy in Years", 
       title = "Economic Growth and Life Expectancy", 
       subtitle = "Data points are country-years", 
       caption = "Source: Gapminder.")
```

**Comments**

+ bin2d takes arguments for both x and y
+ plots counts as a gradient since continuous variables 
+ added regression line and log of x-axis to make it nicer

6. Using midwest data, plot % below poverty line (percbelowpoverty) against % college-educated (percollege). Try this with and without a geom_point() layer

```{r}
p <- ggplot(midwest, mapping = aes(x = percollege, y = percbelowpoverty))
p + geom_density_2d() + 
  labs(title = "geom_density_2d()")

p + geom_density_2d() + 
  geom_point() +
  scale_x_log10() +
  labs(title = "geom_density_2d() + geom_point()")

```

**Comments**

+ density_2d is cool! contour lines around the frequency of observations
+ this reminds me of clusters or medoids in ML
    
    + easy to see this with geom_point layer on top of the density_2d

# Graph Tables, Make Labels, Add Notes

+ Added layer of complexity: 

    1. Learn about how to transform data *before* sending it to ggplot (data wrangling)
        + Better to get things into the right shape before working with ggplot
    2. Explore more geoms and learn how to choose between them
        + Given the data we have vs. visualization we want
        + Subset the data before displaying it
    3. Utilize scale, guide, and theme functions
        + Provides more control over content and appearance of visuals
        + Increases legibility to audience
        + Layer geoms on top of one another
    + We will always be building visuals piece by piece / layer by layer
    + * We want a table of tidy data, a mapping of variables to aesthetic elements, and a particular type of graph
    
## Use Pipes to Summarize Data

+ *column marginals* - numbers sum to 100 by column 
+ *row marginals* - numbers sum to 100 across the rows
+ very easy to lose track of whether R has calculated row margins, column margins, or overall relative frequencies
+ Best Practice: make calculations first, THEN make plots
+ *dplyr* - component of the tidyverse that provides functions for manipulating and reshaping tables of data on the fly
+ goal: summary table with % of religious preferences grouped within a region
+ %>% - allows us to start with a data frame and perform a *sequence* or *pipeline* of operations to turn it into another, usually smaller and more aggregated, table

    + data goes in one side of the pipe, actions are performed via functions, and results come out the other

+ 4 typical pipes: 

    1. *Group* - group the data into the nested structure we want for our summary, such as "Religion by Region" or "Authors by Publications by Year"
    2. *Filter* or *Select* - filter or select pieces of the data by row, column, or both. This gets us the piece of the table we want to work on
    3. *Mutate* - mutate the data by creating new variablse at the *current* level of grouping. This adds new columns to the table without aggregating it
    4. *Summarize* - summarize or aggregate the grouped data. This creates new variables at a *higher* level of grouping. For example we might calculate means with "mean()" or counts with "n()". This results in a smaller, summary table, which we might further summarize or mutate if we want
    
```{r}
# create object
rel_by_region <- gss_sm %>%
  
  # group the rows by bigregion and, within that, by religion
  group_by(bigregion, religion) %>% 
  
  # summarize this table to create a new, much smaller table, with 3 columns: bigregion, religion, and a new summary variable, N, that is a count of the number of observations within each religious group for each region
  summarize(N = n()) %>% 
  
  # with this new table, use the N variable to calculate 2 new columns: relative proportion (freq) and percentage (pct) for each religious category, still grouped by region. Round the results to the nearest percentage point
  mutate(freq = N / sum(N),  # find averages just like in python!
         pct = round((freq*100), 0))

rel_by_region
```

**Comments**
+ Objects on the left side of the pipe "pass through", and whatever is specified on the right of the pipe gets done to that object
+ don't have to keep specifying the name of the underlying data fram object I'm working from
+ everything implicitly carried forward from "gss_sm"
+ Within the pipeline, implicit objects created from summaries and other transformations are carried through also
+ group_by() function sets up how the grouped or nested data will be processed within the summarize(). 

    + Any function used to create a new variable within summarize() (such as mean(), sd(), or n()), will be applied to the *innermost* grouping level first
    + Grouping levels are named from left to right within group_by() from outermost to innermost
    + dplyr summarizes actions and peel off one grouping level at a time, so that the resulting summaries are at the next level up
    + Start with individual-level observations and group them by *religion* within *region*
+ summarize() aggregates the individual observations to counts of the number of people affiliated with each religion, for each region
+ mutate() - adds or removes columns from tables but do not change the grouping level
+ summarize() and mutate() - we can invent named arguments

    + they are the names that the newly created variables in the summary table will have
    
```{r}
rel_by_region %>% 
  group_by(bigregion) %>% 
  summarize(total = sum(pct))
  
```

**Comments**

+ verify the pct values sum to 100 within each region

```{r}
p <- ggplot(rel_by_region, aes(x = bigregion, y = pct, fill = religion))
p + geom_col(position = "dodge2") + 
  labs(x = "Region", y = "Percent", fill = "Religion") + 
       theme(legend.position = "top")
```

**Comments**

+ "dodge2" puts bars side by side

    + default position - proportionally stacked column chart
    + position = "dodge" - stacked within columns (result reads incorrectly)
    + position = "dodge2" - puts the subcategories (religious affiliations) side-by-side within groups (regions)
    
+ still a bad viz. Too many bars side by side. Too crowded
+ dodged charts can be more cleanly expressed as faceted plots
+ faceting removes the need for a legend, thus is simpler for audience to read

```{r}
p <- ggplot(rel_by_region, aes(x = religion, y = pct, fill = religion))
p + geom_col(position = "dodge2") + 
  labs(x = NULL, y = "Percent", fill = "Religion") + 
  guides(fill = FALSE) +
  coord_flip() +
  facet_grid(~ bigregion)
```

**Comments**

+ coord_flip() - switches x and y axes after the plot is made

    + does not remap variables to aesthetics
    
+ dplyr - way to quickly summarize tables of data without having to write code in the body of our ggplot() or geom_ functions

## Continuous Variables by Group or Category

+ Start using "organdata" dataset

```{r}
# look at the data
head(organdata, 10)
vtable(organdata)
summary(organdata)
glimpse(organdata)
organdata %>% select(1:6) %>% sample_n(size = 10)
```

**Comments**

+ Organ procurements rate is a measure of the number of human organs obtained from cadaver organ donors for use in transplant operations
+ Data regarding donation or organs for transplants in 17 OECD countries
+ some missing values ("NA")
+ select() selects columns 1:6

```{r}
# naively plot data and see what happens
# scatterplot of donors vs year
p <- ggplot(organdata, mapping = aes(x = year, y = donors))
p + geom_point()
```

**Comments**

+ if there are heaps of warnings, R will ask me to read them with "warnings()"
+ If want to plot each country's time series using geom_line(), must tell ggplot what the grouping variable is

```{r}
p <- ggplot(organdata, mapping = aes(x = year, y = donors))
p + geom_line(aes(group = country)) +
  facet_wrap(~ country)
```

**Comments**

+ use geom_boxplot() to get a picture of variation by year across countries
+ stat_boxplot() works by default with geom_boxplot() (similar to stat() working with geom_bar())
+ tell geom_boxplot() the variable we want to categorize by "(here, country)" and the continuous variable we want summarized "(here, donors)"

```{r}
p <- ggplot(organdata, mapping = aes(x = country, y = donors))
p + geom_boxplot()
```

**Comments**

+ x-axis is too crowded - names overlap
+ fix this by flipping coords

```{r}
p <- ggplot(organdata, mapping = aes(x = country, y = donors))
p + geom_boxplot() + coord_flip()
```

**Comments**

+ better than previous visual, but not ideal
+ there's no order to this. The audience would be confused
+ reorder(): 2 arguments 

    1. categorical variable or factor that we want to reorder (in this case, country)
    2. variable we want to reorder it by (in this case, donors)
    3. (optional) function wanted to use as a summary statistic (default = reorder categoris of 1st variable by the mean value of 2nd variable)
        + R will fail if using mean() if there are NA's in the data
        + specify it's OK to remove null values (na.rm = TRUE)
        
```{r}
p <- ggplot(organdata, mapping = aes(x = reorder(country, donors, na.rm = TRUE), y = donors))
p + geom_boxplot() + 
  labs(x = NULL) +
  coord_flip()
```

**Comments**

+ since it's obvious these are country names, set labs(x = NULL)

```{r}
p <- ggplot(organdata, mapping = aes(x = reorder(country, donors, na.rm = TRUE), y = donors))
p + geom_violin() + 
  labs(x = NULL) +
  coord_flip()
```

**Comments**

+ same thing as boxplot, but using violin plot instead
+ these are ugly

```{r}
p <- ggplot(organdata, mapping = aes(x = reorder(country, donors, na.rm=TRUE), y = donors, fill = world))
p + geom_boxplot() +
  labs(x = NULL) + 
  coord_flip() + 
  theme(legend.position = "top")
```

**Comments**

+ useful trick - put *categorical variables* on the y-axis to compare their distributions
+ makes it easy to effectively present summary data on more categories
+ geom_point() has argument for "color" but not for "fill" 

```{r}
p <- ggplot(organdata, mapping = aes(x = reorder(country, donors, na.rm = TRUE), y = donors, color = world))
p + geom_point() + 
  labs(x=NULL) + 
  coord_flip() +
  theme(legend.position = "top")
```

**Comments**

+ There are some overplotting of some observations
+ Use geom_jitter() to see points that are plotted on top of each other

```{r}
p <- ggplot(organdata, mapping = aes(x = reorder(country, donors, na.rm=TRUE), y = donors, color = world))
p + geom_jitter() + 
  labs(x=NULL) + 
  coord_flip() + 
  theme(legend.position = "top")
```

**Comments**

+ points are nudge a tiny bit just to show multiple points plotted on the same sport
+ can control amount of "jittering" using "height" and "width" arguments

```{r}
p <- ggplot(organdata, mapping = aes(x = reorder(country, donors, na.rm=TRUE), y = donors, color = world))
p + geom_jitter(position = position_jitter(height = 0.15, width=0.15)) + 
  labs(x=NULL) + 
  coord_flip() + 
  theme(legend.position = "top")
```

**Comments**

+ Did not need "height" argument because it has no effect. 
+ Adding "height" argument results in the same output
+ Use this approach when we want to summarize a categorical variable that just has 1 point per category
+ This method is preferred over bar chart or a table

```{r}
by_country <- organdata %>% 
  group_by(consent_law, country) %>% 
  summarize(donors_mean = mean(donors, na.rm=TRUE), 
            donors_sd = sd(donors, na.rm=TRUE), 
            gdp_mean = mean(gdp, na.rm=TRUE),
            health_mean = mean(health, na.rm=TRUE),
            roads_mean = mean(roads, na.rm=TRUE), 
            cerebvas_mean = mean(cerebvas, na.rm=TRUE))
```

**Comments**

+ 2 steps: 
    
    1. Group data by 'consent_law' and 'country'
    2. Summarize to create 6 new variables, each one of which is the mean or sd of each country's score on a corresponding variable 
    
+ summarize step will inherit information about the original data and gthe grouping and then do its calculations at the innermost grouping level

    + takes all observations for each country and calculates the mean or sd as requested
    
```{r}
by_country
vtable(by_country)
```

**Comments**

+ countries are summarized alphabetically within 'consent_law', which is the outermost grouping variable in the 'group_by()' statement
+ in the pipeline for 'by_county', there are a lot of repeat function calls happening. We can write this more efficiently
+ write a line that applies 'mean()' and 'sd()' functions to every numerical variable in dataset, but *only* numerical ones

```{r}
by_country <- organdata %>% 
  group_by(consent_law, country) %>% 
  summarize_if(is.numeric, funs(mean, sd), na.rm=TRUE) %>% 
  ungroup()
```

**Comments**

+ 'summarize_if()' - examines each column in our data and applies a test to it, only summarizing if the test passes (if return value is TRUE)
+ 'funs()' - list functions we want to apply if return value is TRUE
+ 'ungrou()' - ungroup the data at the end, so that the result is a plain tibble

```{r}
by_country
```

**Comments**

+ all numerical variables have been summarized
+ function applied from 'funs()' is appended to the end of each variable name that it was applied to

    + 'donors_mean'
    + 'donors_sd'
    
```{r}
p <- ggplot(by_country, mapping = aes(x = donors_mean, y = reorder(country, donors_mean), color = consent_law))
p + geom_point(size=3) + 
  labs(x = "Donor Procurement Rate", 
       y = "", color = "Consent Law") + 
  theme(legend.position = "top")
```

**Comments**

+ alternative approach to this; use facet instead of color
+ 'scales = "free_y"' - this usually breaks comparability, but when one axis is categorical, we can free the categorical axis and leave the continuous axis fixed

```{r}
p <- ggplot(by_country, mapping = aes(x = donors_mean, y = reorder(country, donors_mean)))
            
p + geom_point(size=3) + 
  facet_wrap(~ consent_law, scales = "free_y", ncol = 1) + 
  labs(x = "Donor Procurement Rate", 
       y = "")
```

**Comments**

+ Cleveland dotplots are generally preferred to bar or column charts
+ when using these, put the categories on the y-axis and order them in a way that is most relevant to the numerical summary being provided

```{r}
p <- ggplot(by_country, mapping = aes(x = reorder(country, donors_mean), y = donors_mean))

p + geom_pointrange(mapping = aes(ymin = donors_mean - donors_sd, ymax = donors_mean + donors_sd)) +
  labs(x = "", y = "Donor Procurement Rate") + 
  coord_flip()
```

**Comments**

+ 'geom_pointrange()' expects 'y', 'ymin', and 'ymax' as arguments. 
+ We map 'donors_mean' to 'y' and the 'ccode' variable to 'x', 
+ then flip the axes at the end with 'coord_flip()'

## Plot Text Directly

+ 'geom_text()' - use to plot labels along with the points in a scatterplot, or just plot informative labels directly

```{r}
p <- ggplot(by_country, mapping = aes(x = roads_mean, y = donors_mean))
p + geom_point() + 
  geom_text(mapping = aes(label = country))
```

**Comments**

+ 'country' labels are plotted right on top of each point because they are positioned with the same x and y mapping
+ either drop the geom_point or make horizontal adjustment using 'hjust' 

```{r}
p <- ggplot(by_country, mapping = aes(x = roads_mean, y = donors_mean))

p + geom_point() + 
  geom_text(mapping = aes(label = country), hjust = 0)
```

**Comments**

+ 'hjust = 0' - left justify
+ 'hjust = 1' - right justify


```{r}
elections_historic %>% select(2:7)
```

**Comments**

+ Switch datasets to work with some historical US presidential election data via 'socviz' library

```{r}
# could put these labels directly in code, but it is tidier to assign text to objects and pass in the objects
p_title <- "Presidential Elections: Popular & Electoral College Margins"
p_subtitle <- "1824-2016"
p_caption <- "Data for 2016 are provisional."
x_label <- "Winner's share of Popular Vote"
y_label <- "Winner's share of Electoral College Votes"

p <- ggplot(elections_historic, aes(x = popular_pct, y = ec_pct, label = winner_label))

p + geom_hline(yintercept = 0.5, size = 1.4, color = "gray80") + 
  geom_vline(xintercept = 0.5, size = 1.4, color = "gray80") + 
  geom_point() + 
  geom_text_repel() + 
  scale_x_continuous(labels = scales::percent) + 
  scale_y_continuous(labels = scales::percent) + 
  labs(x = x_label, y = y_label, title = p_title, subtitle = p_subtitle, caption = p_caption)
```

**Comments**

+ use 'scale_x_continous()' and 'sclae_y_continuous()' to adjust labels of the scales since shares are stored in the data as proportions (0 to 1) rather than percentages
+ x-axis: popular vote 50% line
+ y-axis: electoral college 50% line
+ 'hline' and 'vline' are plotted at top of code so the points and labels are layered **on top** of them
+ normally it is **NOT** a good idea to label every point on a plot like above. Better approach would be to select a few points of particular interest
+ 'ggrepel' package is consistently favored over using 'geom_text()' 

## Label Outliers

+ to label some points but not others, we must select the points we want to label
+ 'subset()' does the work

```{r}
p <- ggplot(by_country, mapping = aes(x = gdp_mean, y = health_mean))

p + geom_point() + 
  geom_text_repel(data = subset(by_country, gdp_mean > 25000),
                  mapping = aes(label = country))

p <- ggplot(by_country, mapping = aes(x = gdp_mean, y = health_mean))

p + geom_point() + 
  geom_text_repel(data = subset(by_country, 
                                gdp_mean > 25000 | health_mean < 1500 |
                                  country %in% "Belgium"),
                  mapping = aes(label = country))
```

**Comments**

+ 'subset()' - used to create a small dataset on the fly
+ 'subset()' - takes the 'by_country' object and selects only the cases where 'gdp_mean' > 25000

    + only these points are labelled on the plot
    
+ "|" - pipe character represents "or" 

```{r}
organdata$ind <- organdata$ccode %in% c("Ita", "Spa") & organdata$year > 1998

p <- ggplot(organdata, mapping = aes(x = roads, y = donors, color = ind))

p + geom_point() + 
  geom_text_repel(data = subset(organdata, ind),
                  mapping = aes(label = ccode)) + 
  guides(label = FALSE, color = FALSE)
```

**Comments**

+ observation logic - obs is coded as TRUE if ccode is "Ita" or "Spa" **AND** if the 'year' > 1998. 

    + all constraints must be met for observation to be marked as TRUE

## Write and Draw in the Plot Area

+ 'annotate()' - use to point out something important that is not mapped to a variable
    
    + can *use* geoms, temporarily taking advantage of their features in order to place something on the plot
    
```{r}
p <- ggplot(organdata, mapping = aes(x = roads, y = donors))
p + geom_point() + 
  annotate(geom = "text", x = 91, y = 33, 
           label = "A surpringly high \n recovery rate.", 
           hjust = 0)
```

**Comments**

+ I'd rather just use 'ggannotate()' instead

```{r}
p <- ggplot(organdata, 
            mapping = aes(x = roads, y = donors))

p + geom_point() + 
  annotate(geom = "rect", xmin = 125, xmax = 155, 
           ymin = 30, ymax = 35, fill = "red", alpha = 0.2) + 
  annotate(geom = "text", x = 157, y = 33,
           label = "A surprisingly high \n recovery rate.", hjust = 0)
```

**Comments**

+ I'd still rather just use ggannotate() instead

## Understanding Scales, Guides, and Themes

+ 'scale_x_log10()' and 'scale_x_continuous()', and other 'scale_...' functions used to adjust axis labels
+ 'gui9des()' function - remove the legends for a color mapping and a label mapping
+ 'theme()' - move position of  alegend from the side to the top of a figure
+ different plots require different mappings in order to work, and so each 'geom_' function takes mappings tailored to the kind of graph it draws
+ 'scale_' functions: 

    + Every aesthetic mapping has a scale. If you want to adjust how that scale is marked or graduated, then you use a 'scale_' function
    + Many scales come with a legend or key to help the reader interpret the graph. These are called *guides*. You can make adjustments to them with the 'guides()' function. Perhaps the most common use case is to make the legend disappear, as som times it is superfluous. Another is to adjust the arrangement of the key in legends and color bars
    + Graphs have other features not strictly connected to the logical structure of the data being displayed. These include things like their background color, the typeface used for labels, or the placement of the legend on the graph. To adjust these, use the 'theme()' function
    
+ Rule of thumb regarding 'aes()' vs. 'scale_()' and 'geom_()' vs. 'theme()': 

    + If the change you want to make will affect the substantive interpretation of any particular geom, then most likely you will either be mapping an aesthetic to a variable using that geom's 'aes()' function or be specifying a change via some 'scale_' function
    + If the change you want to make does not affect the interpretation of a given 'geom_()', then most likely you will either be setting a variable inside the 'geom_()' function, or making a cosmetic change via the 'theme()' function.
    
```{r}
p <- ggplot(organdata, mapping = aes(x = roads, y = donors, color = world))

p + geom_point()
```

**Comments**

+ every mapped variable has a scale

    + 'roads' mapped to x
    + 'donors' mapped to y
    + 'world' mapped to color
    
+ x and y scales are both *continuous*

    + this is typically the case
    
+ 'world' measure (color or fill scale) is an unordered categorical variable, so its scale is *discrete*

    + this is typically the case
    
+ If x is mapped to a continuous variable, then adding "+ scale_x_continuous()" to the plot statement with no further agruments will have no effect

    + ggplot already understands that the variable is continuous
    + it is already implicitly understood
    
```{r}
p <- ggplot(organdata, mapping = aes(x = roads, y = donors, color = world))
p + geom_point() + 
  scale_x_log10() + 
  scale_y_continuous(breaks = c(5, 15, 25), labels = c("Five", "Fifteen", "Twenty Five"))
```

```{r}
p <- ggplot(organdata, mapping = aes(x = roads, y = donors, color = world))
p + geom_point() + 
  scale_color_discrete(labels = c("Corporatist", "Liberal", "Social Democratic", "Unclassified")) + 
  labs(x = "Road Deaths", 
       y = "Donor Procurement", 
       color = "Welfare State")
```

**Comments**

+ purely cosmetic decisions - use 'theme()' function

```{r}
p <- ggplot(organdata, mapping = aes(x = roads, y = donors, color = world))
p + geom_point() + 
  labs(x = "Road Deaths", 
       y = "Donor Procurement") +
  guides(color = FALSE)
```

**Comments**

+ Removed legend
+ 'scale_()' functions:

    + scale_<mapping>_<kind>()
    
## Where to Go Next

1. Redo fig 5.18 so that it shows all the data points but only labels elections since 1992.See 'elections_historic' dataset to see what variables are available. 

2. Using 'geom_point()' and 'reorder()', make a Cleveland dotplot of all presidential elections, ordered by share of the population vote



3. add a rectangle using 'annotate()' that lightly colors the entire upper left quadrant of figure 5.18



4. Reproduce a pair of graphs from Chapter 1, as seen on 5.28. You will need to filter some rows, group the data by continent, and calculate the mean life expectancy by continent before beinning the plotting process



5. Get comfy with grouping, mutating, and summarizing data in pipelines. Create some grouped objects from the GSS data

```{r}
#gss_sm %>% group_by(race, degree) %>% summarize(N - n()) %>% 
#  mutate(pct = round(N / sum(N) * 100, 0))
```




6. By grouping by 'race' and summing the percentages, check results



7. Calculate mean and median number of children by degree by using functions other than 'sum'



8. Read into 'dplyr' best practices



9. Examine population or life expectancy over time using a series of boxplots using 'gapminder' data. Facet this boxplot by continent. 



10. Experiment with 'notch' and 'varwidth' options for 'geom_boxplot()



11. Swap out 'geom_boxplot()' with 'geom_violin()' to compare



12. Experiment with 'geom_pointrange()' using 'gapminder' or 'organdata' to see how they differ

# Work with Models

```{r}
p <- ggplot(gapminder, mapping = aes(x = log(gdpPercap), y = lifeExp))

p + geom_point(alpha = 0.1) + 
  geom_smooth(color = "tomato", fill = "tomato", method = MASS::rlm) + 
  geom_smooth(color = "steelblue", fill = "steelblue", method = "lm")

p + geom_point(alpha = 0.1) + 
  geom_smooth(color = "tomato", method = "lm", size = 1.2, formula = y ~ splines::bs(x, 3), se = FALSE)

p + geom_point(alpha = 0.1) + 
  geom_quantile(color = "tomato", size = 1.2, method = "rqss", lambda = 1, quantiles = c(0.20, 0.5, 0.85))
```

**Comments**

+ 'stat_' functions compute single numbers or new variables before plotting them for histograms, density plots, boxplots, and other geoms
+ MASS::rlm - 'robust linear model' - fits a robust regression line
+ splines::bs - fit a polynominal curve to the data
+ 'geom_quantile()' - can fit quantil regression lines using a variety of methods

    + quantiles() - takes a vector specifying the quantiles at which to fit the lines
    
## Show Several Fits at Once, with a Legend

+ when plotting multiple layers of 'geom_smooth', always set 'color' and 'fill' to different settings to easily distinguish between each layer
+ it is possible to connect multiple 'geom_smooth' layers and build a legend for it

    + 'scale_color_manual()'
    + 'scale_fill_manual()'

```{r}
model_colors <- RColorBrewer::brewer.pal(3, "Set1")
model_colors  # returns hex values
```

**Comments**

+ returns hex values
+ then, create a plot with 3 different smoothers
+ map color and fill *within the aes() function* as the name of the smoother

```{r}
p0 <- ggplot(gapminder, mapping = aes(x = log(gdpPercap), y = lifeExp))

p1 <- p0 + geom_point(alpha = 0.2) + 
  geom_smooth(method = "lm", aes(color = "OLS", fill = "OLS")) + 
  geom_smooth(method = "lm", formula = y ~ splines::bs(x, df = 3), 
              aes(color = "Cubic Spline", fill = "Cubic Spline")) + 
  geom_smooth(method = "loess", 
              aes(color = "LOESS", fill = "LOESS"))

p1 + scale_color_manual(name = "Models", values = model_colors) + 
  scale_fill_manual(name = "Models", values = model_colors) + 
  theme(legend.position = "top")
```

**Comments**

+ remember that the aes() function is for mapping variables to aesthetics
+ ggplot will properly construct the relevant guide if we call 'scale_color_manual()' and 'scale_fill_manual()'
+ these model-fitting features make ggplot very useful for exploratory work and make it straightforward to generate and compare model-based trends and other summaries as part of the process of descriptive data visualization

## Look Inside Model Objects

+ Key objective always: get from however the object is stored to a tidy table of numbers that we can plot
+ we are always working with objects
+ objects have an internal structure consisting of named pieces

```{r}
gapminder
str(gapminder)
```

**Comments**

+ statistical models in R have an internal structure

```{r}
out <- lm(formula = lifeExp~ gdpPercap + pop + continent, data = gapminder)
```

**Comments**

+ first argument is the formula for the model
+ 'lifeExp' is the dependent variable
+ tilde is used to designate the left and right sides of a model

    + similar to facets, where ~ separates left and right sides
    
```{r}
summary(out)
#str(out)
#out$coefficients
#out$residuals
#out$fitted.values
```

**Comments**

+ like any function, 'summary()' takes its input, performs some actions, and produces output
+ the output above is a mix of information stored inside the model object and partly information that the 'summary()' function has calculated and formatted for display on the screen
+ 'summary()' - selecting and printing only a small amount of core information, in comparison to what is stored in the model object

## Get Model-Based Graphics Right

+ model results typically carry extra burden of interpretation and necessary background knowledge
+ there is no substitute for learning the statistics

### Present your findings in substantive terms

+ Substantive results - showing results in a context where other variables in the analysis are held at sensible values, such as their *means* or *medians*

    + Continuous variables - useful to generate predicted values that cover some substantively meaningful move across the distributions
    + Unordered categorical variables - predicted values might be presented with respect to the modal category in the data
    + often need to convert to a scale that the audience will understand
    
### Show your degree of confidence

+ model estimates come with various measures of precision, confidence, credence, or significance
+ 'geom_ribbon()' - draws filled areas and is useful for plotting ranges of y-axis values along some continuously varying x-axis

### Show your data when you can

+ plotting multivariate models: 

    1. We can show what is in effect a table of coefficients with associated measures of confidence, perhaps organizing the coefficients into meaningful groups, or by the size of the predicted association, or both
    2. We can show the predicted values of some variables (rather than just a model's coefficients) across som range of interest
    
## Generate Predictions to Graph

+ 'predict()' - generic way of using model objects to produce this kind of prediction

    + "generic" functions take their inputs and pass them along to more specific functions behind the scenes, ones that are suited to working with the particular kind of model object we have
    + for 'predict()' to calculate the new values for us, it needs some new data to fit the model to
    + must generate a new data from whose columns have the same names as the variables in the model's original data, but where the rows have new values
    
+ 'expand.grid()' - generates and then will multiply out the full range of values for all combinations of the values we give it, thus creating a new data frame with the new data we need

```{r}
min_gdp <- min(gapminder$gdpPercap)
max_gdp <- max(gapminder$gdpPercap)
med_pop <- median(gapminder$pop)

pred_df <- expand.grid(gdpPercap = (seq(from = min_gdp, to = max_gdp, length.out = 100)), 
                       pop = med_pop, continent = c("Africa", "Americas", "Asia", "Europe", "Oceania"))

dim(pred_df)  ## [1] 500  3

head(pred_df)
```

**Comments**

+ 'dim()' - Dimensions of an Object. Retrieve or set the dimension of an object

```{r}
pred_out <- predict(object = out, newdata = pred_df, interval = "predict")
head(pred_out)
```

**Comments**

+ 'predict()' - if we give the function our new data and model, without any further agrument, it will calculate the fitted values for every row in the data frame
+ using 'interval = "predict"' argument, it wil calculate 95% prediction intervals in addition to the point estimate

```{r}
pred_df <- cbind(pred_df, pred_out)
head(pred_df)
```

**Comments**

+ this is definitely **NOT** best practice
+ this is a tidy data frame

    + contains the predicted values from the model for the range of values we specified
    
```{r}
p <- ggplot(data = subset(pred_df, continent %in% c("Europe", "Africa")), 
            aes(x = gdpPercap, 
                y = fit, ymin = lwr, ymax = upr, 
                color = continent, 
                fill = continent,
                group = continent))

p + geom_point(data = subset(gapminder, continent %in% c("Europe", "Africa")),
               aes(x = gdpPercap, y = lifeExp, 
                   color = continent),
               alpha = 0.5, 
               inherit.aes = FALSE) + 
  geom_line() + 
  geom_ribbon(alpha = 0.2, color = FALSE) + 
  scale_x_log10(labels = scales::dollar)
```

**Comments**

+ OLS predictions
+ 'geom_ribbon()' - ymin and ymax defines the lower and upper limits of the prediction interval
+ 'predict()' - has the ability to work safely with different classes of model that underpines other helper functions in different libraries

## Tidy Model Objects with Broom

+ 'broom' package - library of functions that help us get from the model results that R generates to numbers that we can plot

    + takes model objects and turn pieces of them into data frames that can be used easily with ggplot
    + takes ggplot's approach to tidy data and extends it to the model objects that R produces
    
+ extracts 3 kinds of information: 

    1. *component-level* information about aspects of the model itself, such as coefficients and t-statistics
    2. obtain *observation-l;evel* information about the model's connection to the underlying data
    3. get *model-level* information that summarizes the fit as a whole, such as an F-statistic, the model deviance, or the r-squared
    
### Get component-level statistics with tidy()

+ 'tidy()' - takes a model object and returns a data frame of component-level information

```{r}
out_comp <- tidy(out)
out_comp %>% round_df()
```

**Comments**

+ We are now able to treat this data frame just like all the other data that we have seen so far, and use it to make a plot

```{r}
p <- ggplot(out_comp, mapping = aes(x = term, y = estimate))

p + geom_point() + coord_flip()
```

**Comments**

+ confidence intervals would be nice to know

```{r}
out_conf <- tidy(out, conf.int = TRUE)
out_conf %>% round_df()
```

**Comments**

+ %nin% -  "not in" operator

    + opposite of %in% operator. selects only the items in a first vector of characters that are not in the second
    
+ When fitting a model with categorical variables, R will create coefficient names based on the variable name and category name (e.g. 'continentAmericas')
+ 'prefix_strip()' - drops prefixes to create a new column variable that corresponds to the 'terms' column but has nicer labels

```{r}
out_conf <- subset(out_conf, term %nin% "(Intercept)")
out_conf$nicelabs <- prefix_strip(out_conf$term, "continent")
```

**Comments**

+ 'geom_pointrange()' - displays some information about our confidence in the variable estimates, as opposed to just the coefficients

```{r}
p <- ggplot(out_conf, mapping = aes(x = reorder(nicelabs, estimate), 
                                    y = estimate, ymin = conf.low, ymax = conf.high))
p + geom_pointrange() +
  coord_flip() + 
  labs(x = "", y = "OLS Estimate")
```

**Comments**

+ this displays a nicer plot of OLS estimates and confidence intervals

### Get observation-level statistics with augment()

+ values returned while using 'augment()' are all statistics calculated at the level of the original observations

    + '.fitted' - the fitted values of the model 
    + '.se.fit' - the standard errors of the fitted values
    + '.resid' - the residuals
    + '.hat' - the diagonal errors of the fitted values
    + '.sigma' - an estimate of residual standard deviation when the corresponding observation is dropped from the model
    + '.cooksd' - Cook's distance, a common regression diagnostic
    + '.std.resid' - the standardized residuals
    
```{r}
out_aug <- augment(out)
head(out_aug) %>% round_df()
out_aug <- augment(out, data = gapminder)
head(out_aug) %>% round_df()
```

**Comments**

+ If some rows containing missing data were dropped to fit the model, then these will not be carried over to the augmented data frame

```{r}
p <- ggplot(data = out_aug, mapping = aes(x = .fitted, y = .resid))
p + geom_point()
```

**Comments**

+ possible to plot the residuals vs. fitted values

### Get model-level statistics with glance()

+ 'glance()' - organizes the information typically presented at the bottom of a model's 'summary()' output

```{r}
glance(out) %>% round_df()
```

**Comments**

+ Broom is able to tidy (and augment, and glance at) a wide range of model types

```{r}
out_cph <- coxph(Surv(time, status) ~ age + sex, data = lung)
out_surv <- survfit(out_cph)
```

**Comments**

+ 'Surv()' function - creates the response or outcome variable for the proportional hazards model that is then fitted by the 'coxph()' function
+ 'survfit()' function - creates the survival curve from the model, much like we used 'predict()' to generate predicted values earlier

```{r}
#summary(out_cph)
#summary(out_surv)
out_tidy <- tidy(out_surv)

p <- ggplot(data = out_tidy, mapping = aes(time, estimate))
p + geom_line() + 
  geom_ribbon(mapping = aes(ymin = conf.low, ymax = conf.high), alpha = 0.2)
```

### Grouped Analysis and List Columns

+ 'Broom' makes it possible to quickly fit models to different subsets of your data and get consistent and usable tables of results out the other end
+ gapminder data is organized by 'country-years' - the unit over observation in the rows

```{r}
eu77 <- gapminder %>% 
  filter(continent == 'Europe', year == 1977)

fit <- lm(lifeExp ~ log(gdpPercap), data = eu77)
summary(fit)
```

**Comments**

+ This looks at the gapminder data by examining the relationship between life expectancy and GDP by *continent*, for each year in the data
+ We start with our table of data and then %>% group the countries by 'continent' and 'year' using the 'group_by()' function
+ our data is reorganized first by continent, and within continent by year

```{r}
out_let <- gapminder %>% 
  group_by(continent, year) %>% 
  nest()

out_le
```

**Comments**

+ 'nest()' - resulting object has the tabular form we expect (tibble)
+ *list column* - useful for bundling together complex objects (structured, such as tibbles)
+ look at the data by filtering the data and then *unnesting* the list column

```{r}
out_le %>% filter(continent == "Europe" & year == 1977) %>% 
  unnest()
```

**Comments**

+ *list columns* - useful because we can act on them in a compact and tidy way
+ pass functions along to each row of the *list column* and make something happen

```{r}
# helper function to estimate a particular OLS model on some data
fit_ols <- function(df){
  lm(lifeExp ~ log(gdpPercap), data = df)
}

out_le <- gapminder %>% 
  group_by(continent, year) %>% 
  nest() %>% 
  mutate(model = map(data, fit_ols))

out_le
```

**Comments**

+ functions are a kind of object


```{r}
fit_ols <- function(df){
  lm(lifeExp ~ log(gdpPercap), data = df)
}

out_tidy <- gapminder %>% 
  group_by(continent, year) %>% 
  nest() %>% 
  mutate(model = map(data, fit_ols),
         tidied = map(model, tidy)) %>% 
  unnest(tidied, .drop = TRUE) %>% 
  filter(term %nin% "(Intercept)" &
           continent %nin% "Oceania")

out_tidy %>% sample_n(5, replace = TRUE)

```

**Comments**

+ error in my 'sample_n()' function
+ added 'replace = TRUE' as suggested by warning message
+ output is different from the book

```{r}
p <- ggplot(data = out_tidy, 
            mapping = aes(x = year, y = estimate, 
                          ymin = estimate - 2*std.error,
                          ymax = estimate + 2*std.error,
                          group = continent, color = continent))

p + geom_pointrange(position = position_dodge(width = 1)) + 
  scale_x_continuous(breaks = unique(gapminder$year)) + 
  theme(legend.position = "top") + 
  labs(x = "Year", y = "Estimate", color = "Continent")
```

**Comments**

+ The call to 'position_dodge()' within 'geom_pointrange()' allows the point ranges for each continent to be near one another within years, instead of being plotted right on top of one another
+ this approach is good when we're interested in seeing how OLS performs against some other model specification

## Plot Marginal Effects



# Draw Maps

```{r}

```


# Refine your Plots

```{r}

```


